{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import sys\n",
    "import subprocess\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_name():\n",
    "    return(line_split[8].split(\"gene_name \")[1].split('''\"''')[1])\n",
    "def get_transcript_name():\n",
    "    try:\n",
    "        return(line_split[8].split(\"transcript_id \")[1].split('''\"''')[1])\n",
    "    except:\n",
    "        print(\"Error: SparK tried to extract information to plot genes in the selected area from the following line in the gtf file but failed. Please check the format thoroughly, and read the SparK github page for how the gtf needs to be structured for genes to be plotted, or how to change this python script to work with this specific gtf.\")\n",
    "        print(line_split)\n",
    "def draw_line(coordinates, thickness, color):\n",
    "    output = '''<path d=\"'''\n",
    "    for x, i in enumerate(coordinates):\n",
    "        if x == 0:\n",
    "            output += \"M \"\n",
    "        else:\n",
    "            output += \" L \"\n",
    "        output += str(i[1]) + \" \" + str(y_start - i[0])\n",
    "    output += '''\" style=\"stroke:'''+ color + '''; stroke-width:'''+ str(thickness) +'''; fill:none \"/>'''\n",
    "    return(output)\n",
    "\n",
    "def get_lines_tabix(filename, stretch):\n",
    "    \"\"\"\n",
    "    helper function for make_raw_data_filled().\n",
    "    If a data file is tabix-indexed, retrieve the desired region using tabix.\n",
    "    \"\"\"\n",
    "    chromname = stretch[0]\n",
    "    if len(stretch) > 3:\n",
    "        # Chromosome name was modified. Use original name with\n",
    "        # tabix index.\n",
    "        chromname = stretch[3]\n",
    "    tabix_cmd = subprocess.Popen(['tabix', filename, \\\n",
    "        '{}:{}-{}'.format(chromname, stretch[1], stretch[2])], \\\n",
    "        stdout=subprocess.PIPE)\n",
    "    out, err = tabix_cmd.communicate()\n",
    "    for line in out.decode().strip().split('\\n'):\n",
    "        if line != \"\":\n",
    "            yield line\n",
    "\n",
    "def get_lines_stream(filename):\n",
    "    \"\"\"\n",
    "    helper function for make_raw_data_filled().\n",
    "    If a data file is not tabix-indexed, go through it line by line.\n",
    "    \"\"\"\n",
    "    if filename[-3:] == '.gz':\n",
    "        f = gzip.open(filename, 'r')\n",
    "        for line in f:\n",
    "            yield line.rstrip()\n",
    "    else:\n",
    "        f = open(filename, 'r')\n",
    "        for line in f:\n",
    "            yield line.rstrip()\n",
    "    f.close()\n",
    "\n",
    "def make_raw_data_filled(stretch, files, offset):  # files[ctrl,treat]\n",
    "    raw_data_filled = [[0] * (stretch[2] - stretch[1]) for r in range(len(files))]\n",
    "    for a, datafile2 in enumerate(files):\n",
    "        # Check to see whether the file is tabix-indexed. If so, use index for\n",
    "        # faster processing\n",
    "        input_lines = None\n",
    "        found_chromosome = False\n",
    "        if os.path.isfile('{}.tbi'.format(datafile2)):\n",
    "            input_lines = get_lines_tabix(datafile2, stretch)\n",
    "            # Lines will already be in the specified interval.\n",
    "            found_chromosome = True\n",
    "        else:\n",
    "            print(\"WARNING: {} is not tabix-indexed.\".format(datafile2), \\\n",
    "                file=sys.stderr)\n",
    "            print(\"To speed up, compress with bgzip and index with tabix.\", \\\n",
    "                file=sys.stderr)\n",
    "            input_lines = get_lines_stream(datafile2)\n",
    "        \n",
    "        for line in input_lines:\n",
    "            line_split = line.split(\"\\t\")\n",
    "            try:\n",
    "                if line_split[0][:3] == \"chr\" or line_split[0][:3] == \"Chr\":\n",
    "                    line_split[0] = line_split[0][3:]\n",
    "            except:\n",
    "                pass\n",
    "            if found_chromosome and line_split[0] != stretch[0]:\n",
    "                break\n",
    "\n",
    "            if line_split[0] == stretch[0]:\n",
    "                try:\n",
    "                    line_split[3] = float(line_split[3].split(\"\\n\")[0])\n",
    "                except:\n",
    "                    print(\"Warning! Could not import following row from: \" + datafile2)\n",
    "                    print(line)\n",
    "                    print(\"Continuing to Import...\")\n",
    "                    print(\"\")\n",
    "                found_chromosome = True\n",
    "                if int(line_split[2]) >= stretch[1] + offset:\n",
    "                    if int(line_split[1]) <= stretch[2] + offset:\n",
    "                        for iteration in range(int(line_split[2]) - int(line_split[1])):\n",
    "                            try:\n",
    "                                raw_data_filled[a][int(line_split[1]) + iteration - stretch[1] + offset] = line_split[3]\n",
    "                            except:\n",
    "                                pass\n",
    "\n",
    "    # shrink to max_datapoints if bigger\n",
    "    max_datapoints = 2000\n",
    "    if stretch[2] - stretch[1] > max_datapoints:\n",
    "        binfactor_split = math.modf(float((float(stretch[2] - stretch[1]))/max_datapoints))  # get values after and before period\n",
    "        binfactor = sum(binfactor_split)\n",
    "        temp_data = [[] for u in range(len(files))]  # new data list\n",
    "        for workingfilenr in range(len(files)):\n",
    "            for position in range(max_datapoints):\n",
    "                start_postition_split = math.modf(position * binfactor)  # after and before period\n",
    "\n",
    "                # first add fraction of start position or entire value if no fraction\n",
    "                temp_value = float(raw_data_filled[workingfilenr][(int(start_postition_split[1]))] * (1 - start_postition_split[0]))\n",
    "                binfactor_left = binfactor - (1 - start_postition_split[0])\n",
    "\n",
    "                # add all values with no fractions\n",
    "                iteration = 0\n",
    "                while binfactor_left > 1:\n",
    "                    temp_value += raw_data_filled[workingfilenr][int(start_postition_split[1]) + 1 + iteration]\n",
    "                    iteration += 1\n",
    "                    binfactor_left -= 1\n",
    "\n",
    "                # add last fraction or value if no fraction\n",
    "                if binfactor_left > 0:\n",
    "                    if float((start_postition_split[1]) + 1 + iteration) < len(raw_data_filled[0]):\n",
    "                        temp_value += raw_data_filled[workingfilenr][int(start_postition_split[1]) + 1 + iteration] * binfactor_left\n",
    "                        temp_data[workingfilenr].append(temp_value/sum(binfactor_split))\n",
    "        raw_data_filled = copy.deepcopy(temp_data)\n",
    "\n",
    "    if smoothen_tracks is not None:\n",
    "        raw_data_filled_smooth = [[0] * 2000 for r in range(len(files))]\n",
    "        for x, dataset in enumerate(raw_data_filled):\n",
    "            temp = [dataset[0]] * smoothen_tracks\n",
    "            for p, i in enumerate(dataset):\n",
    "                temp.append(i)\n",
    "                temp.pop(0)\n",
    "                raw_data_filled_smooth[x][p] = np.average(temp)\n",
    "        raw_data_filled = copy.deepcopy(raw_data_filled_smooth)\n",
    "    return raw_data_filled\n",
    "def write_to_file(row):\n",
    "    with open(output_filename, \"a\") as f:\n",
    "        f.write(row)\n",
    "        f.write(\"\\n\")\n",
    "def get_max_value(datasets1, datasets2):\n",
    "    plottingaverages = False\n",
    "    if show_plots == \"averages\":\n",
    "        plottingaverages = True\n",
    "    max_1 = []\n",
    "    for datafile1 in datasets1:\n",
    "        max_1.append(max(datafile1))\n",
    "    max_2 = []\n",
    "    for datafile2 in datasets2:\n",
    "        max_2.append(max(datafile2))\n",
    "    if plottingaverages == True:\n",
    "        if max_2 != []:\n",
    "            if max_2 != []:\n",
    "                return max([np.average(max_1), np.average(max_2)])\n",
    "            else:\n",
    "                return(np.average(max_1))\n",
    "    elif plottingaverages == False:\n",
    "        if max_2 != []:\n",
    "            return max([max(max_1), max(max_2)])\n",
    "        else:\n",
    "            return(max(max_1))\n",
    "def get_relative_hight(raw_value): # FIX make sure maxvalue can be 0 too\n",
    "    if raw_value == 0:\n",
    "        return(0)\n",
    "    else:\n",
    "        return((raw_value * hight * relative_track_hight_percentage) / max_value) # to not go up to the max\n",
    "def draw_rect(x_coord, y_0, color, width, hight1, opacity):\n",
    "    return '''<rect x=\"''' + str(x_coord) + '''\" opacity=\"''' + str(opacity) + '''\" y=\"''' + str(y_0 - hight1) + '''\" fill=\"''' + color + '''\" width=\"''' + str(width) + '''\" height=\"''' + str(hight1) + '''\"/>'''\n",
    "def draw_polygon(coordinates, opacity, color, stroke_width):\n",
    "    for q, w in enumerate(coordinates):\n",
    "        coordinates[q][0] = y_start - coordinates[q][0]\n",
    "    string = '''<polygon points=\"'''\n",
    "    for h, c in enumerate(coordinates):\n",
    "        if h == 0:\n",
    "            string += str(c[1]) + \",\" + str(c[0])\n",
    "        else:\n",
    "            string += \" \" + str(c[1]) + \",\" + str(c[0])\n",
    "    string += '''\" opacity=\"''' + str(opacity) + '''\" fill=\"''' + color + '''\"''' + ''' stroke=\"black\" stroke-width=\"''' + str(stroke_width) + '''\"/>'''\n",
    "    return string\n",
    "def draw_standard_spark():\n",
    "    if len(control_data) > 1 and len(treat_data) > 1:\n",
    "        last_xpos = -1\n",
    "        coords = []  # y/x, spark color\n",
    "        last_value = \"\"\n",
    "        for x, value in enumerate(control_data[0]):\n",
    "            x_pos = x_start + (x * quantile)  # y/x\n",
    "            ctrl_values = []\n",
    "            treat_values = []\n",
    "            for p, i in enumerate(control_data):\n",
    "                ctrl_values.append(control_data[p][x])\n",
    "            for p, i in enumerate(treat_data):\n",
    "                treat_values.append(treat_data[p][x])\n",
    "\n",
    "            sum_std = np.std(ctrl_values) + np.std(treat_values)\n",
    "            if abs(np.average(ctrl_values) - np.average(treat_values)) > sum_std:\n",
    "                if np.average(ctrl_values) > np.average(treat_values):\n",
    "                    if last_value == \"\" or last_value == \"up\":\n",
    "                        if (last_xpos + 1) == x:\n",
    "                            coords.append([get_relative_hight(np.average(ctrl_values) - np.std(ctrl_values)), x_pos])\n",
    "                            coords.insert(0, [get_relative_hight(np.average(treat_values) + np.std(treat_values)), x_pos])\n",
    "                            last_xpos = x\n",
    "                        else:\n",
    "                            if len(coords) > 0:\n",
    "                                write_to_file(draw_polygon(coords, 0.8, spark_color[1], stroke_width_spark))\n",
    "                            coords = [[get_relative_hight(np.average(ctrl_values) - np.std(ctrl_values)), x_pos]]\n",
    "                            coords.insert(0, [get_relative_hight(np.average(treat_values) + np.std(treat_values)), x_pos])\n",
    "                            last_xpos = x\n",
    "                            last_value = \"up\"\n",
    "                    else:\n",
    "                        if len(coords) > 0:\n",
    "                            write_to_file(draw_polygon(coords, 0.8, spark_color[0], stroke_width_spark))\n",
    "                        coords = [[get_relative_hight(np.average(ctrl_values) - np.std(ctrl_values)), x_pos]]\n",
    "                        coords.insert(0, [get_relative_hight(np.average(treat_values) + np.std(treat_values)), x_pos])\n",
    "                        last_xpos = x\n",
    "                        last_value = \"up\"\n",
    "\n",
    "                if np.average(ctrl_values) < np.average(treat_values):\n",
    "                    if last_value == \"\" or last_value == \"down\":\n",
    "                        if (last_xpos + 1) == x:\n",
    "                            coords.append([get_relative_hight(np.average(treat_values) - np.std(treat_values)), x_pos])\n",
    "                            coords.insert(0, [get_relative_hight(np.average(ctrl_values) + np.std(ctrl_values)), x_pos])\n",
    "                            last_xpos = x\n",
    "                        else:\n",
    "                            if len(coords) > 0:\n",
    "                                write_to_file(draw_polygon(coords, 0.8, spark_color[0], stroke_width_spark))\n",
    "                            coords = [[get_relative_hight(np.average(treat_values) - np.std(treat_values)), x_pos]]\n",
    "                            coords.insert(0, [get_relative_hight(np.average(ctrl_values) + np.std(ctrl_values)), x_pos])\n",
    "                            last_xpos = x\n",
    "                            last_value = \"down\"\n",
    "                    else:\n",
    "                        if len(coords) > 0:\n",
    "                            write_to_file(draw_polygon(coords, 0.8, spark_color[1], stroke_width_spark))\n",
    "                        coords = [[get_relative_hight(np.average(treat_values) - np.std(treat_values)), x_pos]]\n",
    "                        coords.insert(0, [get_relative_hight(np.average(ctrl_values) + np.std(ctrl_values)), x_pos])\n",
    "                        last_xpos = x\n",
    "                        last_value = \"down\"\n",
    "        if len(coords) > 0:\n",
    "            if last_value == \"up\":\n",
    "                write_to_file(draw_polygon(coords, spark_opacity, spark_color[0], stroke_width_spark))\n",
    "            elif last_value == \"down\":\n",
    "                write_to_file(draw_polygon(coords, spark_opacity, spark_color[1], stroke_width_spark))\n",
    "    else:\n",
    "        print(\"Error: Some Sparks not plotted as sparks require at least 2 control and treatment files per plot\")\n",
    "def get_region_to_draw():\n",
    "    region_to_draw = 0\n",
    "    if line_split[4] > region[1] and line_split[3] < region[2]: # check if there is something to draw\n",
    "        region_to_draw = [float(line_split[3]), float(line_split[4])]\n",
    "        if line_split[3] < region[1]:\n",
    "            region_to_draw[0] = float(region[1])\n",
    "        if line_split[4] > region[2]:\n",
    "            region_to_draw[1] = float(region[2])\n",
    "    return(region_to_draw)\n",
    "\n",
    "\n",
    "# Additional Arguments #########################################\n",
    "hight = 30  # hight of plots\n",
    "x_start = 50\n",
    "spark_opacity = 1\n",
    "stroke_width = 0  # 0.1 stroke widths good\n",
    "stroke_width_spark = 0\n",
    "plot_all_TSS = False  ## could plot all TSS sites\n",
    "relative_track_hight_percentage = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-33d20a1f0516>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-scale'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'--display_scalebar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'set to \"no\" to remove scalebar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequired\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"yes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python/3.6.3/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1728\u001b[0m     \u001b[0;31m# =====================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python/3.6.3/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1760\u001b[0m         \u001b[0;31m# parse the arguments and exit if there are any errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_UNRECOGNIZED_ARGS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_UNRECOGNIZED_ARGS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python/3.6.3/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   1995\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequired_actions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m             self.error(_('the following arguments are required: %s') %\n\u001b[0;32m-> 1997\u001b[0;31m                        ', '.join(required_actions))\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m         \u001b[0;31m# make sure all required groups had one option present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python/3.6.3/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/python/3.6.3/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
